{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import chess\n",
    "from chessboard import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>+56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...</td>\n",
       "      <td>+52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958030</th>\n",
       "      <td>r1bqkb1r/pp3ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1P...</td>\n",
       "      <td>+6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958031</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1...</td>\n",
       "      <td>+84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958032</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1BN2N2/PP2Q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958033</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/1BN2N2/PP2Q...</td>\n",
       "      <td>+115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958034</th>\n",
       "      <td>r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/2N2N2/PPB1Q...</td>\n",
       "      <td>+45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12958035 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        FEN Evaluation\n",
       "0         rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...        -10\n",
       "1         rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...        +56\n",
       "2         rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...         -9\n",
       "3         rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...        +52\n",
       "4         rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...        -26\n",
       "...                                                     ...        ...\n",
       "12958030  r1bqkb1r/pp3ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1P...         +6\n",
       "12958031  r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1B3N2/PP2Q1...        +84\n",
       "12958032  r2qkb1r/pp1b1ppp/1nn1p3/3pP3/3P1P2/1BN2N2/PP2Q...          0\n",
       "12958033  r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/1BN2N2/PP2Q...       +115\n",
       "12958034  r2qkb1r/pp1b1ppp/1n2p3/n2pP3/3P1P2/2N2N2/PPB1Q...        +45\n",
       "\n",
       "[12958035 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_path=\"d:\\OneDrive - Indian Institute of Technology Bombay\\Study\\Events and Activities\\Year 2\\Seasons of Coding 23\\soc23-DeepCarlsen\"\n",
    "TotalPos = pd.read_csv(abs_path+\"\\dataset\\chessDataEval.csv\", )\n",
    "TotalPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond(arr):\n",
    "    pos = arr[\"FEN\"].split()[0]\n",
    "    res = pos.count('Q')>1 or pos.count('B')>2 or pos.count('N')>2 or pos.count('R')>2 or pos.count('q')>1 or pos.count('b')>2 or pos.count('n')>2 or pos.count('r')>2\n",
    "    return not res\n",
    "dataset_raw = TotalPos[TotalPos.apply(cond, axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/3k4/p2P4/P2K4/1p6/5N1p/8/8 w - - 0 55</td>\n",
       "      <td>#+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2rr1k1/p1q2pp1/2pNp2p/2Pn4/Q6P/PP4P1/5PB1/R3R...</td>\n",
       "      <td>+152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5rk1/p5rp/3p1nq1/2pP1p2/2P1pP2/P3N3/1R2Q1PP/1R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b5/5pkp/2r3p1/p7/PbR1N3/4P3/4B1PP/6K1 b - - 1 36</td>\n",
       "      <td>-205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/8/3B2k1/8/4KP1P/8/4b3/8 b - - 0 46</td>\n",
       "      <td>+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nr4k1/4p1bp/p2p2p1/PqpPp3/Nr2P3/4BP1P/1PQ2RP1/...</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>r1n2rk1/4ppbp/b2p2p1/P1qP4/2p5/6P1/1PQBPPBP/1R...</td>\n",
       "      <td>+68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>r1b1k2r/ppp3bp/n2p1np1/1N1P4/2P1Pp2/8/PP3BPP/2...</td>\n",
       "      <td>+31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r4rk1/1p4pp/4b3/p1Pp3q/1P1Qnp2/P2B1N2/5PPP/2KR...</td>\n",
       "      <td>+74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rn2kb1r/1bqppppp/5n2/1Bp5/8/1QN1P3/PP2NPPP/R1B...</td>\n",
       "      <td>+144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 FEN Evaluation\n",
       "0            8/3k4/p2P4/P2K4/1p6/5N1p/8/8 w - - 0 55       #+18\n",
       "1  b2rr1k1/p1q2pp1/2pNp2p/2Pn4/Q6P/PP4P1/5PB1/R3R...       +152\n",
       "2  5rk1/p5rp/3p1nq1/2pP1p2/2P1pP2/P3N3/1R2Q1PP/1R...          0\n",
       "3  2b5/5pkp/2r3p1/p7/PbR1N3/4P3/4B1PP/6K1 b - - 1 36       -205\n",
       "4               8/8/3B2k1/8/4KP1P/8/4b3/8 b - - 0 46        +13\n",
       "5  nr4k1/4p1bp/p2p2p1/PqpPp3/Nr2P3/4BP1P/1PQ2RP1/...        -37\n",
       "6  r1n2rk1/4ppbp/b2p2p1/P1qP4/2p5/6P1/1PQBPPBP/1R...        +68\n",
       "7  r1b1k2r/ppp3bp/n2p1np1/1N1P4/2P1Pp2/8/PP3BPP/2...        +31\n",
       "8  r4rk1/1p4pp/4b3/p1Pp3q/1P1Qnp2/P2B1N2/5PPP/2KR...        +74\n",
       "9  rn2kb1r/1bqppppp/5n2/1Bp5/8/1QN1P3/PP2NPPP/R1B...       +144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset_raw.sample(10)\n",
    "dataset.reset_index(inplace=True)\n",
    "dataset = dataset.drop([\"index\"], axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_global(arr):\n",
    "    fen = arr if isinstance(arr, str) else arr[\"FEN\"]\n",
    "    board = chess.Board(fen)\n",
    "    white_play = (board.turn==chess.WHITE)\n",
    "    K = board.has_kingside_castling_rights(chess.WHITE)\n",
    "    k = board.has_kingside_castling_rights(chess.BLACK)\n",
    "    Q = board.has_queenside_castling_rights(chess.WHITE)\n",
    "    q = board.has_queenside_castling_rights(chess.BLACK)\n",
    "    return [int(white_play),int(K), int(k), int(Q), int(q)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_piece(arr):\n",
    "    def p(symbol):\n",
    "        return chess.Piece.from_symbol(symbol)\n",
    "    fen = arr if isinstance(arr, str) else arr[\"FEN\"]\n",
    "    board = chess.Board(fen)\n",
    "    pieces_map = chess.Board.piece_map(board)\n",
    "    emp = [-1,-1]\n",
    "    piece_num = [0]*14\n",
    "    piece_w = [emp]*16  # K Q B(light) B(dark) N N R R P P P P P P P P\n",
    "    piece_b = [emp]*16  # k q b(light) b(dark) n n r r p p p p p p p p\n",
    "    for (loc, pi) in pieces_map.items():\n",
    "        if pi== p('k'):\n",
    "            piece_b[0] = [loc%8,loc//8]\n",
    "            piece_num[7]+=1\n",
    "        elif pi== p('q'):\n",
    "            piece_b[1] = [loc%8,loc//8]\n",
    "            piece_num[8]+=1\n",
    "        elif pi== p('b'):\n",
    "            if((loc%8+loc//8)%2!=0):\n",
    "                piece_b[2] = [loc%8,loc//8]\n",
    "                piece_num[9]+=1\n",
    "            else:\n",
    "                piece_b[3] = [loc%8,loc//8]\n",
    "                piece_num[10]+=1\n",
    "        elif pi== p('n'):\n",
    "            piece_b[piece_b[4:6].index(emp)+4]=[loc%8,loc//8]\n",
    "            piece_num[11]+=1\n",
    "        elif pi== p('r'):\n",
    "            piece_b[piece_b[6:8].index(emp)+6]=[loc%8,loc//8]\n",
    "            piece_num[12]+=1\n",
    "        elif pi== p('p'):\n",
    "            piece_b[piece_b[8:16].index(emp)+8]=[loc%8,loc//8]\n",
    "            piece_num[13]+=1\n",
    "\n",
    "        elif pi== p('K'):\n",
    "            piece_w[0] = [loc%8,loc//8]\n",
    "            piece_num[0]+=1\n",
    "        elif pi== p('Q'):\n",
    "            piece_w[1] = [loc%8,loc//8]\n",
    "            piece_num[1]+=1\n",
    "        elif pi== p('B'):\n",
    "            if((loc%8+loc//8)%2!=0):\n",
    "                piece_w[2] = [loc%8,loc//8]\n",
    "                piece_num[2]+=1\n",
    "            else:\n",
    "                piece_w[3] = [loc%8,loc//8]\n",
    "                piece_num[3]+=1\n",
    "        elif pi== p('N'):\n",
    "            piece_w[piece_w[4:6].index(emp)+4]=[loc%8,loc//8]\n",
    "            piece_num[4]+=1\n",
    "        elif pi== p('R'):\n",
    "            piece_w[piece_w[6:8].index(emp)+6]=[loc%8,loc//8]\n",
    "            piece_num[5]+=1\n",
    "        elif pi== p('P'):\n",
    "            piece_w[piece_w[8:16].index(emp)+8]=[loc%8,loc//8]\n",
    "            piece_num[6]+=1\n",
    "    result = piece_num+[item for sublist in piece_w for item in sublist]+[item for sublist in piece_b for item in sublist]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_map(arr):\n",
    "    fen = arr if isinstance(arr, str) else arr[\"FEN\"]\n",
    "    piece_value = {6:1, 5:9, 3:3, 2:3, 4:5, 1:1}\n",
    "    #piece_value = {6:0, 5:1340, 3:425, 2:450, 4:680, 1:110}\n",
    "    board = chess.Board(fen)\n",
    "    wht = []\n",
    "    wht_count = []\n",
    "    blk = []\n",
    "    blk_count = []\n",
    "    for sq in chess.SQUARES:   \n",
    "        attks_white = chess.BaseBoard.attackers(board, chess.WHITE, sq)\n",
    "        attks_black = chess.BaseBoard.attackers(board, chess.BLACK, sq)\n",
    "        wht.append(0 if len(attks_white)==0 else min(piece_value[chess.BaseBoard.piece_type_at(board, sq2)] for sq2 in attks_white))\n",
    "        blk.append(0 if len(attks_black)==0 else min(piece_value[chess.BaseBoard.piece_type_at(board, sq2)] for sq2 in attks_black))\n",
    "        wht_count.append(len(attks_white))\n",
    "        blk_count.append(len(attks_black))\n",
    "    return wht_count+wht+blk_count+blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_ex(fen):\n",
    "    f_centric = features_piece(fen)\n",
    "    f_global = features_global(fen)\n",
    "    f_map = features_map(fen)\n",
    "    f_global.extend(f_centric[:14])\n",
    "    f_centric=f_centric[14:]\n",
    "    return f_global, f_centric, f_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdleaf():\n",
    "    input1 = tf.keras.Input(shape=(19))\n",
    "    input2 = tf.keras.Input(shape=(64))\n",
    "    input3 = tf.keras.Input(shape=(256))\n",
    "    #flat3 = tf.keras.layers.Flatten()(input3)\n",
    "\n",
    "    batch_1 = tf.keras.layers.BatchNormalization()(input1)\n",
    "    batch_2 = tf.keras.layers.BatchNormalization()(input2)\n",
    "    #batch_3 = tf.keras.layers.BatchNormalization()(flat3)\n",
    "\n",
    "    in1_layer = tf.keras.layers.Dense(units=19, activation=tf.nn.relu)(batch_1)\n",
    "    in2_layer = tf.keras.layers.Dense(units=64, activation=tf.nn.relu)(batch_2)\n",
    "    in3_layer = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)(input3)\n",
    "\n",
    "    concat_layer = tf.keras.layers.Concatenate()([in1_layer, in2_layer, in3_layer])\n",
    "\n",
    "    hid1 = tf.keras.layers.Dense(units=92, activation=tf.nn.relu)(concat_layer)\n",
    "    #hid2 = tf.keras.layers.Dense(units=96, activation=tf.nn.relu)(hid1)\n",
    "    #hid3 = tf.keras.layers.Dense(units=5, activation=tf.nn.relu)(hid2)\n",
    "    out = tf.keras.layers.Dense(units=1, activation=tf.nn.tanh)(hid1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input1, input2, input3], outputs=out)\n",
    "    return model\n",
    "eval_model = tdleaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tens(arra):\n",
    "    t =  tf.convert_to_tensor(np.asarray(arra).astype(np.float_))\n",
    "    return tf.reshape(t,(1, len(t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9049155712127686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,x2,x3 = feat_ex(\"6Q1/1p4nk/p7/P3p2q/1KPB4/1P6/8/8 b - - 1 53\")\n",
    "prev_res = eval_model([tens(el) for el in [x1,x2,x3]])\n",
    "float(prev_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['batch_normalization/gamma:0', 'batch_normalization/beta:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'batch_normalization/gamma:0' shape=(19,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>), (None, <tf.Variable 'batch_normalization/beta:0' shape=(19,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>), (None, <tf.Variable 'batch_normalization_1/gamma:0' shape=(64,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>), (None, <tf.Variable 'batch_normalization_1/beta:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense/kernel:0' shape=(19, 19) dtype=float32, numpy=\narray([[ 2.67158121e-01, -2.29079828e-01, -1.48719549e-02,\n         3.86737794e-01,  1.82744175e-01, -3.68126512e-01,\n         3.04241091e-01,  3.82236689e-01, -3.33912551e-01,\n        -7.08981752e-02,  1.86821967e-01, -1.55165106e-01,\n        -3.01229596e-01, -2.23546848e-01,  9.77111757e-02,\n         7.89057016e-02,  1.93191856e-01,  3.90496582e-01,\n        -2.10678414e-01],\n       [ 6.46730363e-02,  4.29111719e-02, -3.39246988e-02,\n         5.25377691e-02, -3.77353519e-01, -2.85696089e-01,\n        -8.89773965e-02,  6.90463185e-02, -1.89855397e-01,\n        -1.21742129e-01,  1.87096506e-01, -2.50707924e-01,\n         3.01800072e-02, -2.51566052e-01, -6.78514838e-02,\n         1.22365326e-01,  3.89828414e-01,  7.51250982e-02,\n        -3.80514532e-01],\n       [ 3.19877893e-01, -1.15746647e-01, -3.24147940e-01,\n        -3.42267126e-01, -1.17249668e-01, -2.69926280e-01,\n        -1.82111800e-01, -2.95321077e-01,  2.75115460e-01,\n         7.53523707e-02, -3.84333909e-01, -2.98765272e-01,\n        -1.93433076e-01,  1.86015874e-01,  3.65379781e-01,\n        -3.06087077e-01, -2.70018280e-02, -2.46947780e-01,\n         3.29142779e-01],\n       [ 3.33251387e-01,  3.65261465e-01,  1.67057008e-01,\n        -2.74749190e-01,  2.57606000e-01,  3.47132593e-01,\n        -1.06294453e-01,  4.00639176e-02,  5.53188920e-02,\n         3.77595395e-01,  2.87922055e-01,  2.71574885e-01,\n        -2.05210701e-01, -1.89533755e-01,  5.62895834e-02,\n         9.84695554e-02,  3.13825905e-02,  2.48247892e-01,\n         2.88041025e-01],\n       [-2.63850749e-01,  1.94780231e-02,  2.49369115e-01,\n         1.60814315e-01, -1.28423423e-01,  2.27540225e-01,\n         3.65740657e-02,  2.52579004e-01,  1.67730361e-01,\n        -1.20016485e-01, -2.08184630e-01, -2.59136677e-01,\n        -3.45211953e-01,  2.88648874e-01,  1.71129674e-01,\n         2.74170607e-01, -1.45276070e-01,  2.64135897e-02,\n         1.44171715e-03],\n       [-1.61748156e-01, -1.59130648e-01, -3.70620668e-01,\n        -6.43005371e-02, -3.23803723e-02, -3.78296912e-01,\n         3.20152372e-01, -1.82162106e-01, -2.39987195e-01,\n         1.43165320e-01, -1.40615076e-01, -2.65327811e-01,\n        -1.10037059e-01,  1.87328368e-01,  2.91939676e-02,\n        -2.14402467e-01, -2.82165110e-01,  3.63173336e-01,\n        -2.54042238e-01],\n       [ 1.16686434e-01,  1.04909927e-01,  8.16321671e-02,\n         9.99799669e-02,  1.02672786e-01, -6.57044649e-02,\n        -1.73119366e-01, -3.69150043e-01,  1.58877403e-01,\n        -7.24333227e-02,  3.34849358e-02,  3.52616221e-01,\n        -3.87158990e-01,  3.53514045e-01,  3.70693833e-01,\n        -6.54706359e-02, -6.02489710e-02,  1.44595116e-01,\n         3.65984172e-01],\n       [-1.45280719e-01, -1.87596560e-01, -2.65906274e-01,\n         4.37791646e-02,  3.34616870e-01,  1.94425374e-01,\n         3.11516255e-01,  3.71067077e-01,  3.33148390e-01,\n        -1.43597513e-01, -1.76705122e-02, -2.34276205e-01,\n        -3.42897415e-01,  8.93213749e-02, -1.51776701e-01,\n        -3.91633213e-02, -3.11578661e-01, -2.14816272e-01,\n         3.61136943e-01],\n       [-2.80867279e-01,  4.57482040e-02,  3.94215077e-01,\n         1.64042801e-01,  2.83258468e-01, -2.44063959e-01,\n         3.11248988e-01, -2.93068290e-01,  2.83897191e-01,\n         2.08743602e-01, -1.22126967e-01, -3.19064498e-01,\n        -3.76663536e-01,  3.80586356e-01, -3.34441960e-01,\n         1.74803644e-01, -3.76097381e-01,  3.79653871e-02,\n         2.78387040e-01],\n       [ 2.46015936e-01,  4.93788421e-02, -1.21975482e-01,\n         3.14871103e-01,  1.99663252e-01,  2.17178077e-01,\n         3.78410488e-01, -2.34103501e-01,  2.14620143e-01,\n        -3.03252339e-02, -1.31621301e-01,  2.28801399e-01,\n        -3.50941241e-01,  3.55289966e-01,  1.02778941e-01,\n        -8.43077898e-04,  9.74255800e-03, -8.61178339e-02,\n        -5.66014647e-02],\n       [ 3.70130807e-01,  2.90972799e-01,  7.20717013e-02,\n        -2.55909145e-01, -1.11956447e-01,  2.59304345e-02,\n         3.92198563e-05, -1.87994242e-02,  4.13068831e-02,\n         3.62009734e-01, -3.57230306e-02, -5.98516464e-02,\n        -2.44108483e-01, -4.44444120e-02, -1.66987360e-01,\n         2.91596085e-01, -8.07311237e-02, -3.68489176e-01,\n         1.21721774e-01],\n       [ 6.57512546e-02, -8.05901587e-02,  1.05225444e-02,\n         2.56796807e-01,  3.21417183e-01,  2.58496732e-01,\n        -2.88940936e-01, -3.55082810e-01, -5.22001386e-02,\n         2.81756669e-01,  4.29969132e-02, -3.51767629e-01,\n         2.22418875e-01,  2.63683528e-01, -2.66679138e-01,\n         2.20556557e-02,  6.38327301e-02,  2.88882762e-01,\n        -4.81010079e-02],\n       [ 1.87789232e-01, -2.10718960e-01, -3.51987064e-01,\n        -1.98842227e-01,  2.72399396e-01, -1.04057312e-01,\n         2.06444263e-02,  1.99904889e-01, -1.43523216e-02,\n        -2.14927316e-01,  7.42258430e-02,  1.66872829e-01,\n         3.91252428e-01,  1.44781560e-01,  4.93660569e-02,\n        -1.52571648e-01, -5.93861938e-02,  3.25395554e-01,\n         1.51945561e-01],\n       [-2.03979313e-02,  4.95879054e-02, -4.83871996e-02,\n         1.99558705e-01, -3.78602922e-01, -2.34068260e-01,\n        -1.43849850e-03,  6.17839992e-02, -6.10136092e-02,\n         2.34807760e-01, -1.02773309e-01,  3.48053724e-01,\n        -1.08024925e-01, -1.40047371e-02,  1.45048827e-01,\n        -7.45843351e-02,  3.69464666e-01,  1.07355982e-01,\n         3.43736708e-02],\n       [-2.72975713e-01, -3.94577533e-01, -1.76784769e-01,\n         2.26458520e-01, -3.84182423e-01, -1.40519857e-01,\n         2.57567436e-01,  2.21616119e-01,  3.17544907e-01,\n         9.16980803e-02,  3.63674492e-01, -1.03072971e-01,\n        -2.48040497e-01, -3.16925943e-01,  1.79507166e-01,\n        -2.72435218e-01,  3.55189472e-01, -3.78964633e-01,\n         2.34913796e-01],\n       [ 7.91262686e-02, -5.02488017e-02,  2.26680487e-01,\n        -3.57692927e-01, -3.76210690e-01, -1.30493641e-01,\n        -3.76406401e-01,  3.90643626e-01,  3.36159199e-01,\n         2.71542042e-01,  2.41001457e-01,  3.17335695e-01,\n        -1.92149088e-01,  1.13112479e-01, -9.47046280e-03,\n         9.71186161e-02, -2.71947414e-01, -1.09305322e-01,\n         9.26651657e-02],\n       [-1.64931267e-01, -9.39993560e-02,  7.37139881e-02,\n        -2.63600647e-02,  2.11723357e-01,  4.97242510e-02,\n         3.08742791e-01, -2.64838099e-01, -3.59163076e-01,\n         3.09835583e-01,  8.05046856e-02,  5.24262786e-02,\n        -3.64045858e-01,  3.43846291e-01,  2.86999345e-03,\n        -2.81790793e-01,  1.49262160e-01, -2.25945115e-02,\n        -2.95101166e-01],\n       [-5.29873967e-02,  1.47229582e-01, -2.63917148e-02,\n         2.23978966e-01, -3.68740976e-01, -1.00221068e-01,\n        -2.84318119e-01,  1.76386386e-01, -1.99367553e-01,\n         2.95889527e-01, -1.23542249e-01, -3.26935053e-02,\n         5.49846590e-02, -1.34240538e-01, -3.69596839e-01,\n         1.30087107e-01,  3.97169679e-01,  3.35005254e-01,\n         2.50592619e-01],\n       [ 3.32723528e-01,  2.63145775e-01, -1.29869223e-01,\n        -1.60863876e-01,  1.87285691e-01,  1.22240156e-01,\n         3.81767422e-01,  2.05369323e-01, -2.98916936e-01,\n        -3.19350600e-01, -1.21035963e-01,  3.38807195e-01,\n         1.15077764e-01,  4.27293777e-02, -1.35016739e-02,\n         2.44204670e-01, -1.45000488e-01, -1.25951797e-01,\n        -2.04344094e-02]], dtype=float32)>), (None, <tf.Variable 'dense/bias:0' shape=(19,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_1/kernel:0' shape=(64, 64) dtype=float32, numpy=\narray([[-0.19458422, -0.0851595 , -0.17545757, ...,  0.1078461 ,\n         0.00474761,  0.07973318],\n       [ 0.0126487 , -0.13213027,  0.18551333, ...,  0.04104786,\n         0.09495173, -0.17498086],\n       [ 0.20880307,  0.10029398, -0.10990803, ..., -0.01578601,\n         0.19698213, -0.03408939],\n       ...,\n       [ 0.17537959, -0.12748595, -0.21202834, ...,  0.05063291,\n        -0.21034591, -0.0196607 ],\n       [ 0.11892395,  0.08304332,  0.17103939, ...,  0.10765202,\n        -0.1977478 , -0.1266081 ],\n       [ 0.05705808, -0.01903455, -0.17595394, ...,  0.16103993,\n        -0.15206595, -0.17731741]], dtype=float32)>), (None, <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_2/kernel:0' shape=(256, 256) dtype=float32, numpy=\narray([[-0.10289536,  0.09874135, -0.00093769, ..., -0.07681069,\n        -0.04273641,  0.04775242],\n       [ 0.09700543, -0.08810423, -0.09008623, ...,  0.05444068,\n        -0.05993759,  0.02841946],\n       [-0.08603986, -0.07156242,  0.01612806, ...,  0.06516465,\n        -0.07396403,  0.00362049],\n       ...,\n       [ 0.0203423 ,  0.00255788, -0.03367206, ...,  0.04354265,\n         0.08167406,  0.06159324],\n       [ 0.06108663,  0.07060107,  0.03200956, ...,  0.10794736,\n        -0.05114865, -0.04506523],\n       [-0.01804383, -0.04395057, -0.01042758, ...,  0.0548358 ,\n         0.05374274, -0.03495073]], dtype=float32)>), (None, <tf.Variable 'dense_2/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'dense_3/kernel:0' shape=(339, 92) dtype=float32, numpy=\narray([[ 0.09453578,  0.05479926, -0.1136406 , ..., -0.07537091,\n        -0.10084742, -0.11667444],\n       [-0.01241502, -0.03711192,  0.06418322, ..., -0.07766712,\n        -0.01838445, -0.05472601],\n       [ 0.04174158, -0.0329996 , -0.00881024, ...,  0.05405305,\n        -0.05094609,  0.04284963],\n       ...,\n       [ 0.02798223, -0.08136231,  0.03525837, ...,  0.0578045 ,\n        -0.10654862, -0.01398934],\n       [-0.11370932, -0.09277577, -0.0094333 , ..., -0.11122292,\n         0.09545596, -0.09843222],\n       [ 0.01390323, -0.04368902,  0.08413161, ..., -0.10176723,\n        -0.00640013,  0.07304478]], dtype=float32)>), (None, <tf.Variable 'dense_3/bias:0' shape=(92,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_4/kernel:0' shape=(92, 1) dtype=float32, numpy=\narray([[-0.24574347],\n       [ 0.2124165 ],\n       [ 0.20175931],\n       [ 0.24018657],\n       [-0.08672239],\n       [ 0.17243066],\n       [-0.03286169],\n       [ 0.00209841],\n       [-0.13549204],\n       [-0.00835384],\n       [ 0.17297551],\n       [ 0.23852703],\n       [-0.08847451],\n       [ 0.1514717 ],\n       [ 0.19094098],\n       [-0.08243836],\n       [ 0.24829555],\n       [ 0.1744358 ],\n       [ 0.17341393],\n       [ 0.12508217],\n       [ 0.19763875],\n       [ 0.15060207],\n       [ 0.13156524],\n       [ 0.16393521],\n       [-0.0707939 ],\n       [ 0.18534255],\n       [-0.14841653],\n       [-0.236885  ],\n       [ 0.04321754],\n       [ 0.01323262],\n       [-0.06665649],\n       [ 0.0092001 ],\n       [ 0.06380945],\n       [-0.03448424],\n       [ 0.17377609],\n       [-0.17037724],\n       [ 0.07351631],\n       [-0.09291139],\n       [-0.2076    ],\n       [ 0.10783407],\n       [-0.08001924],\n       [-0.2377769 ],\n       [ 0.13582662],\n       [ 0.06811866],\n       [-0.02949739],\n       [-0.00118428],\n       [-0.1783087 ],\n       [-0.10204971],\n       [-0.05215245],\n       [-0.22193919],\n       [-0.13809097],\n       [-0.13043833],\n       [ 0.05080429],\n       [-0.15512785],\n       [ 0.2053456 ],\n       [-0.09361556],\n       [ 0.05622923],\n       [ 0.16909268],\n       [ 0.121288  ],\n       [ 0.18620199],\n       [ 0.2434532 ],\n       [-0.1473114 ],\n       [ 0.15638897],\n       [-0.03430843],\n       [ 0.04372865],\n       [-0.22665481],\n       [-0.10454248],\n       [-0.00048357],\n       [-0.02881992],\n       [-0.00938776],\n       [ 0.21649656],\n       [ 0.15446153],\n       [ 0.17256841],\n       [-0.09767739],\n       [ 0.13000637],\n       [ 0.06529579],\n       [ 0.01746178],\n       [-0.22652982],\n       [ 0.05876634],\n       [ 0.1934016 ],\n       [ 0.01705396],\n       [ 0.00952002],\n       [-0.00554176],\n       [ 0.04678959],\n       [ 0.22758317],\n       [ 0.03490785],\n       [-0.12846158],\n       [ 0.08620581],\n       [-0.22444327],\n       [-0.13576674],\n       [ 0.09562409],\n       [-0.0371387 ]], dtype=float32)>), (None, <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive - Indian Institute of Technology Bombay\\Study\\Events and Activities\\Year 2\\Seasons of Coding 23\\soc23-DeepCarlsen\\final.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m   \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mbatch_size):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m# Grab a batch of training data and propagate through the network\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     loss \u001b[39m=\u001b[39m step(dataset, eval_model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(epoch)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(num_epochs)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m      idx*b=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(idx\u001b[39m*\u001b[39mbatch_size)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39m1000\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m      Loss=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(loss))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m# Record the loss and plot the evolution of the loss as a function of training\u001b[39;00m\n",
      "\u001b[1;32md:\\OneDrive - Indian Institute of Technology Bombay\\Study\\Events and Activities\\Year 2\\Seasons of Coding 23\\soc23-DeepCarlsen\\final.ipynb Cell 12\u001b[0m in \u001b[0;36mstep\u001b[1;34m(dataset, model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(tf\u001b[39m.\u001b[39mconvert_to_tensor(loss_list\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(dataset), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32), model\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(grads)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(grads, model\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss_list\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(dataset)\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\keras\\optimizers\\optimizer.py:1173\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1169\u001b[0m experimental_aggregate_gradients \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\n\u001b[0;32m   1170\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mexperimental_aggregate_gradients\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m )\n\u001b[0;32m   1172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_gradients_aggregation \u001b[39mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m-> 1173\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate_gradients(grads_and_vars)\n\u001b[0;32m   1174\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\keras\\optimizers\\optimizer.py:1139\u001b[0m, in \u001b[0;36mOptimizer.aggregate_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate_gradients\u001b[39m(\u001b[39mself\u001b[39m, grads_and_vars):\n\u001b[0;32m   1128\u001b[0m     \u001b[39m\"\"\"Aggregate gradients on all devices.\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \n\u001b[0;32m   1130\u001b[0m \u001b[39m    By default we will perform reduce_sum of gradients across devices. Users\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[39m      List of (gradient, variable) pairs.\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1139\u001b[0m     \u001b[39mreturn\u001b[39;00m optimizer_utils\u001b[39m.\u001b[39;49mall_reduce_sum_gradients(grads_and_vars)\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\keras\\optimizers\\utils.py:33\u001b[0m, in \u001b[0;36mall_reduce_sum_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m\"\"\"Returns all-reduced gradients aggregated via summation.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m  List of (gradient, variable) pairs where gradients have been all-reduced.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(grads_and_vars)\n\u001b[1;32m---> 33\u001b[0m filtered_grads_and_vars \u001b[39m=\u001b[39m filter_empty_gradients(grads_and_vars)\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m filtered_grads_and_vars:\n\u001b[0;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mstrategy_supports_no_merge_call():\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\keras\\optimizers\\utils.py:77\u001b[0m, in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filtered:\n\u001b[0;32m     76\u001b[0m     variable \u001b[39m=\u001b[39m ([v\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m _, v \u001b[39min\u001b[39;00m grads_and_vars],)\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo gradients provided for any variable: \u001b[39m\u001b[39m{\u001b[39;00mvariable\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProvided `grads_and_vars` is \u001b[39m\u001b[39m{\u001b[39;00mgrads_and_vars\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m vars_with_empty_grads:\n\u001b[0;32m     82\u001b[0m     logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     83\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGradients do not exist for variables \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m when minimizing the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mloss. If you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre using `model.compile()`, did you forget to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprovide a `loss` argument?\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m         ([v\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m vars_with_empty_grads]),\n\u001b[0;32m     87\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: (['batch_normalization/gamma:0', 'batch_normalization/beta:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'batch_normalization/gamma:0' shape=(19,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>), (None, <tf.Variable 'batch_normalization/beta:0' shape=(19,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>), (None, <tf.Variable 'batch_normalization_1/gamma:0' shape=(64,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>), (None, <tf.Variable 'batch_normalization_1/beta:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense/kernel:0' shape=(19, 19) dtype=float32, numpy=\narray([[ 2.67158121e-01, -2.29079828e-01, -1.48719549e-02,\n         3.86737794e-01,  1.82744175e-01, -3.68126512e-01,\n         3.04241091e-01,  3.82236689e-01, -3.33912551e-01,\n        -7.08981752e-02,  1.86821967e-01, -1.55165106e-01,\n        -3.01229596e-01, -2.23546848e-01,  9.77111757e-02,\n         7.89057016e-02,  1.93191856e-01,  3.90496582e-01,\n        -2.10678414e-01],\n       [ 6.46730363e-02,  4.29111719e-02, -3.39246988e-02,\n         5.25377691e-02, -3.77353519e-01, -2.85696089e-01,\n        -8.89773965e-02,  6.90463185e-02, -1.89855397e-01,\n        -1.21742129e-01,  1.87096506e-01, -2.50707924e-01,\n         3.01800072e-02, -2.51566052e-01, -6.78514838e-02,\n         1.22365326e-01,  3.89828414e-01,  7.51250982e-02,\n        -3.80514532e-01],\n       [ 3.19877893e-01, -1.15746647e-01, -3.24147940e-01,\n        -3.42267126e-01, -1.17249668e-01, -2.69926280e-01,\n        -1.82111800e-01, -2.95321077e-01,  2.75115460e-01,\n         7.53523707e-02, -3.84333909e-01, -2.98765272e-01,\n        -1.93433076e-01,  1.86015874e-01,  3.65379781e-01,\n        -3.06087077e-01, -2.70018280e-02, -2.46947780e-01,\n         3.29142779e-01],\n       [ 3.33251387e-01,  3.65261465e-01,  1.67057008e-01,\n        -2.74749190e-01,  2.57606000e-01,  3.47132593e-01,\n        -1.06294453e-01,  4.00639176e-02,  5.53188920e-02,\n         3.77595395e-01,  2.87922055e-01,  2.71574885e-01,\n        -2.05210701e-01, -1.89533755e-01,  5.62895834e-02,\n         9.84695554e-02,  3.13825905e-02,  2.48247892e-01,\n         2.88041025e-01],\n       [-2.63850749e-01,  1.94780231e-02,  2.49369115e-01,\n         1.60814315e-01, -1.28423423e-01,  2.27540225e-01,\n         3.65740657e-02,  2.52579004e-01,  1.67730361e-01,\n        -1.20016485e-01, -2.08184630e-01, -2.59136677e-01,\n        -3.45211953e-01,  2.88648874e-01,  1.71129674e-01,\n         2.74170607e-01, -1.45276070e-01,  2.64135897e-02,\n         1.44171715e-03],\n       [-1.61748156e-01, -1.59130648e-01, -3.70620668e-01,\n        -6.43005371e-02, -3.23803723e-02, -3.78296912e-01,\n         3.20152372e-01, -1.82162106e-01, -2.39987195e-01,\n         1.43165320e-01, -1.40615076e-01, -2.65327811e-01,\n        -1.10037059e-01,  1.87328368e-01,  2.91939676e-02,\n        -2.14402467e-01, -2.82165110e-01,  3.63173336e-01,\n        -2.54042238e-01],\n       [ 1.16686434e-01,  1.04909927e-01,  8.16321671e-02,\n         9.99799669e-02,  1.02672786e-01, -6.57044649e-02,\n        -1.73119366e-01, -3.69150043e-01,  1.58877403e-01,\n        -7.24333227e-02,  3.34849358e-02,  3.52616221e-01,\n        -3.87158990e-01,  3.53514045e-01,  3.70693833e-01,\n        -6.54706359e-02, -6.02489710e-02,  1.44595116e-01,\n         3.65984172e-01],\n       [-1.45280719e-01, -1.87596560e-01, -2.65906274e-01,\n         4.37791646e-02,  3.34616870e-01,  1.94425374e-01,\n         3.11516255e-01,  3.71067077e-01,  3.33148390e-01,\n        -1.43597513e-01, -1.76705122e-02, -2.34276205e-01,\n        -3.42897415e-01,  8.93213749e-02, -1.51776701e-01,\n        -3.91633213e-02, -3.11578661e-01, -2.14816272e-01,\n         3.61136943e-01],\n       [-2.80867279e-01,  4.57482040e-02,  3.94215077e-01,\n         1.64042801e-01,  2.83258468e-01, -2.44063959e-01,\n         3.11248988e-01, -2.93068290e-01,  2.83897191e-01,\n         2.08743602e-01, -1.22126967e-01, -3.19064498e-01,\n        -3.76663536e-01,  3.80586356e-01, -3.34441960e-01,\n         1.74803644e-01, -3.76097381e-01,  3.79653871e-02,\n         2.78387040e-01],\n       [ 2.46015936e-01,  4.93788421e-02, -1.21975482e-01,\n         3.14871103e-01,  1.99663252e-01,  2.17178077e-01,\n         3.78410488e-01, -2.34103501e-01,  2.14620143e-01,\n        -3.03252339e-02, -1.31621301e-01,  2.28801399e-01,\n        -3.50941241e-01,  3.55289966e-01,  1.02778941e-01,\n        -8.43077898e-04,  9.74255800e-03, -8.61178339e-02,\n        -5.66014647e-02],\n       [ 3.70130807e-01,  2.90972799e-01,  7.20717013e-02,\n        -2.55909145e-01, -1.11956447e-01,  2.59304345e-02,\n         3.92198563e-05, -1.87994242e-02,  4.13068831e-02,\n         3.62009734e-01, -3.57230306e-02, -5.98516464e-02,\n        -2.44108483e-01, -4.44444120e-02, -1.66987360e-01,\n         2.91596085e-01, -8.07311237e-02, -3.68489176e-01,\n         1.21721774e-01],\n       [ 6.57512546e-02, -8.05901587e-02,  1.05225444e-02,\n         2.56796807e-01,  3.21417183e-01,  2.58496732e-01,\n        -2.88940936e-01, -3.55082810e-01, -5.22001386e-02,\n         2.81756669e-01,  4.29969132e-02, -3.51767629e-01,\n         2.22418875e-01,  2.63683528e-01, -2.66679138e-01,\n         2.20556557e-02,  6.38327301e-02,  2.88882762e-01,\n        -4.81010079e-02],\n       [ 1.87789232e-01, -2.10718960e-01, -3.51987064e-01,\n        -1.98842227e-01,  2.72399396e-01, -1.04057312e-01,\n         2.06444263e-02,  1.99904889e-01, -1.43523216e-02,\n        -2.14927316e-01,  7.42258430e-02,  1.66872829e-01,\n         3.91252428e-01,  1.44781560e-01,  4.93660569e-02,\n        -1.52571648e-01, -5.93861938e-02,  3.25395554e-01,\n         1.51945561e-01],\n       [-2.03979313e-02,  4.95879054e-02, -4.83871996e-02,\n         1.99558705e-01, -3.78602922e-01, -2.34068260e-01,\n        -1.43849850e-03,  6.17839992e-02, -6.10136092e-02,\n         2.34807760e-01, -1.02773309e-01,  3.48053724e-01,\n        -1.08024925e-01, -1.40047371e-02,  1.45048827e-01,\n        -7.45843351e-02,  3.69464666e-01,  1.07355982e-01,\n         3.43736708e-02],\n       [-2.72975713e-01, -3.94577533e-01, -1.76784769e-01,\n         2.26458520e-01, -3.84182423e-01, -1.40519857e-01,\n         2.57567436e-01,  2.21616119e-01,  3.17544907e-01,\n         9.16980803e-02,  3.63674492e-01, -1.03072971e-01,\n        -2.48040497e-01, -3.16925943e-01,  1.79507166e-01,\n        -2.72435218e-01,  3.55189472e-01, -3.78964633e-01,\n         2.34913796e-01],\n       [ 7.91262686e-02, -5.02488017e-02,  2.26680487e-01,\n        -3.57692927e-01, -3.76210690e-01, -1.30493641e-01,\n        -3.76406401e-01,  3.90643626e-01,  3.36159199e-01,\n         2.71542042e-01,  2.41001457e-01,  3.17335695e-01,\n        -1.92149088e-01,  1.13112479e-01, -9.47046280e-03,\n         9.71186161e-02, -2.71947414e-01, -1.09305322e-01,\n         9.26651657e-02],\n       [-1.64931267e-01, -9.39993560e-02,  7.37139881e-02,\n        -2.63600647e-02,  2.11723357e-01,  4.97242510e-02,\n         3.08742791e-01, -2.64838099e-01, -3.59163076e-01,\n         3.09835583e-01,  8.05046856e-02,  5.24262786e-02,\n        -3.64045858e-01,  3.43846291e-01,  2.86999345e-03,\n        -2.81790793e-01,  1.49262160e-01, -2.25945115e-02,\n        -2.95101166e-01],\n       [-5.29873967e-02,  1.47229582e-01, -2.63917148e-02,\n         2.23978966e-01, -3.68740976e-01, -1.00221068e-01,\n        -2.84318119e-01,  1.76386386e-01, -1.99367553e-01,\n         2.95889527e-01, -1.23542249e-01, -3.26935053e-02,\n         5.49846590e-02, -1.34240538e-01, -3.69596839e-01,\n         1.30087107e-01,  3.97169679e-01,  3.35005254e-01,\n         2.50592619e-01],\n       [ 3.32723528e-01,  2.63145775e-01, -1.29869223e-01,\n        -1.60863876e-01,  1.87285691e-01,  1.22240156e-01,\n         3.81767422e-01,  2.05369323e-01, -2.98916936e-01,\n        -3.19350600e-01, -1.21035963e-01,  3.38807195e-01,\n         1.15077764e-01,  4.27293777e-02, -1.35016739e-02,\n         2.44204670e-01, -1.45000488e-01, -1.25951797e-01,\n        -2.04344094e-02]], dtype=float32)>), (None, <tf.Variable 'dense/bias:0' shape=(19,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_1/kernel:0' shape=(64, 64) dtype=float32, numpy=\narray([[-0.19458422, -0.0851595 , -0.17545757, ...,  0.1078461 ,\n         0.00474761,  0.07973318],\n       [ 0.0126487 , -0.13213027,  0.18551333, ...,  0.04104786,\n         0.09495173, -0.17498086],\n       [ 0.20880307,  0.10029398, -0.10990803, ..., -0.01578601,\n         0.19698213, -0.03408939],\n       ...,\n       [ 0.17537959, -0.12748595, -0.21202834, ...,  0.05063291,\n        -0.21034591, -0.0196607 ],\n       [ 0.11892395,  0.08304332,  0.17103939, ...,  0.10765202,\n        -0.1977478 , -0.1266081 ],\n       [ 0.05705808, -0.01903455, -0.17595394, ...,  0.16103993,\n        -0.15206595, -0.17731741]], dtype=float32)>), (None, <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_2/kernel:0' shape=(256, 256) dtype=float32, numpy=\narray([[-0.10289536,  0.09874135, -0.00093769, ..., -0.07681069,\n        -0.04273641,  0.04775242],\n       [ 0.09700543, -0.08810423, -0.09008623, ...,  0.05444068,\n        -0.05993759,  0.02841946],\n       [-0.08603986, -0.07156242,  0.01612806, ...,  0.06516465,\n        -0.07396403,  0.00362049],\n       ...,\n       [ 0.0203423 ,  0.00255788, -0.03367206, ...,  0.04354265,\n         0.08167406,  0.06159324],\n       [ 0.06108663,  0.07060107,  0.03200956, ...,  0.10794736,\n        -0.05114865, -0.04506523],\n       [-0.01804383, -0.04395057, -0.01042758, ...,  0.0548358 ,\n         0.05374274, -0.03495073]], dtype=float32)>), (None, <tf.Variable 'dense_2/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'dense_3/kernel:0' shape=(339, 92) dtype=float32, numpy=\narray([[ 0.09453578,  0.05479926, -0.1136406 , ..., -0.07537091,\n        -0.10084742, -0.11667444],\n       [-0.01241502, -0.03711192,  0.06418322, ..., -0.07766712,\n        -0.01838445, -0.05472601],\n       [ 0.04174158, -0.0329996 , -0.00881024, ...,  0.05405305,\n        -0.05094609,  0.04284963],\n       ...,\n       [ 0.02798223, -0.08136231,  0.03525837, ...,  0.0578045 ,\n        -0.10654862, -0.01398934],\n       [-0.11370932, -0.09277577, -0.0094333 , ..., -0.11122292,\n         0.09545596, -0.09843222],\n       [ 0.01390323, -0.04368902,  0.08413161, ..., -0.10176723,\n        -0.00640013,  0.07304478]], dtype=float32)>), (None, <tf.Variable 'dense_3/bias:0' shape=(92,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_4/kernel:0' shape=(92, 1) dtype=float32, numpy=\narray([[-0.24574347],\n       [ 0.2124165 ],\n       [ 0.20175931],\n       [ 0.24018657],\n       [-0.08672239],\n       [ 0.17243066],\n       [-0.03286169],\n       [ 0.00209841],\n       [-0.13549204],\n       [-0.00835384],\n       [ 0.17297551],\n       [ 0.23852703],\n       [-0.08847451],\n       [ 0.1514717 ],\n       [ 0.19094098],\n       [-0.08243836],\n       [ 0.24829555],\n       [ 0.1744358 ],\n       [ 0.17341393],\n       [ 0.12508217],\n       [ 0.19763875],\n       [ 0.15060207],\n       [ 0.13156524],\n       [ 0.16393521],\n       [-0.0707939 ],\n       [ 0.18534255],\n       [-0.14841653],\n       [-0.236885  ],\n       [ 0.04321754],\n       [ 0.01323262],\n       [-0.06665649],\n       [ 0.0092001 ],\n       [ 0.06380945],\n       [-0.03448424],\n       [ 0.17377609],\n       [-0.17037724],\n       [ 0.07351631],\n       [-0.09291139],\n       [-0.2076    ],\n       [ 0.10783407],\n       [-0.08001924],\n       [-0.2377769 ],\n       [ 0.13582662],\n       [ 0.06811866],\n       [-0.02949739],\n       [-0.00118428],\n       [-0.1783087 ],\n       [-0.10204971],\n       [-0.05215245],\n       [-0.22193919],\n       [-0.13809097],\n       [-0.13043833],\n       [ 0.05080429],\n       [-0.15512785],\n       [ 0.2053456 ],\n       [-0.09361556],\n       [ 0.05622923],\n       [ 0.16909268],\n       [ 0.121288  ],\n       [ 0.18620199],\n       [ 0.2434532 ],\n       [-0.1473114 ],\n       [ 0.15638897],\n       [-0.03430843],\n       [ 0.04372865],\n       [-0.22665481],\n       [-0.10454248],\n       [-0.00048357],\n       [-0.02881992],\n       [-0.00938776],\n       [ 0.21649656],\n       [ 0.15446153],\n       [ 0.17256841],\n       [-0.09767739],\n       [ 0.13000637],\n       [ 0.06529579],\n       [ 0.01746178],\n       [-0.22652982],\n       [ 0.05876634],\n       [ 0.1934016 ],\n       [ 0.01705396],\n       [ 0.00952002],\n       [-0.00554176],\n       [ 0.04678959],\n       [ 0.22758317],\n       [ 0.03490785],\n       [-0.12846158],\n       [ 0.08620581],\n       [-0.22444327],\n       [-0.13576674],\n       [ 0.09562409],\n       [-0.0371387 ]], dtype=float32)>), (None, <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>))."
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 2\n",
    "learning_rate = 5e-4\n",
    "td_len = 1\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss_history = []\n",
    "\n",
    "def step(dataset, model):\n",
    "    def best_move(board, model):\n",
    "        turn = int(board.turn==chess.WHITE)\n",
    "        moves_set = board.legal_moves\n",
    "        moves_set2 = []\n",
    "        eval_set = []\n",
    "        try:\n",
    "            for move in moves_set:\n",
    "                board.push(move)\n",
    "                fen = board.fen()\n",
    "                x1,x2,x3 = feat_ex(fen)\n",
    "                eval_set.append(model([tens(el) for el in [x1,x2,x3]]))\n",
    "                moves_set2.append(move)\n",
    "                board.pop()\n",
    "        except:\n",
    "            return move, 7000\n",
    "        res = max(eval_set)\n",
    "        bmove = moves_set2[eval_set.index(res)]\n",
    "        return bmove, res\n",
    "             \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_list = 0\n",
    "        for row, element in dataset.iterrows():\n",
    "            board = chess.Board(element[\"FEN\"])\n",
    "            fen = board.fen()\n",
    "            x1,x2,x3 = feat_ex(fen)\n",
    "            prev_res = float(model([tens(el) for el in [x1,x2,x3]])[0][0])\n",
    "            y_temp = int(element[\"Evaluation\"])/10000 if '#' not in element[\"Evaluation\"] else 1 if '+' in element[\"Evaluation\"] else -1\n",
    "            loss = prev_res-y_temp\n",
    "            lmda = 0.7\n",
    "\n",
    "            #for move_td in range(td_len):\n",
    "             #   bmove, res = best_move(board, model)\n",
    "              #  board.push(bmove)\n",
    "               # loss = lmda*loss+(res-prev_res)**2\n",
    "                #prev_res = res\n",
    "            loss_list = loss_list+loss\n",
    "    grads = tape.gradient(tf.convert_to_tensor(loss_list/len(dataset), dtype=tf.float32), model.trainable_variables)\n",
    "    print(grads)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss_list/len(dataset)\n",
    "\n",
    "# The training loop!\n",
    "for epoch in range(num_epochs):\n",
    "  for idx in range(len(dataset)//batch_size):\n",
    "    # Grab a batch of training data and propagate through the network\n",
    "    loss = step(dataset, eval_model)\n",
    "    print(\"Epoch=\"+str(epoch)+\"/\"+str(num_epochs)+\"      idx*b=\"+str(idx*batch_size)+\"/\"+str(1000)+\"      Loss=\"+str(loss))\n",
    "    # Record the loss and plot the evolution of the loss as a function of training\n",
    "    loss_history.append(loss.numpy().mean())\n",
    "\n",
    "loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive - Indian Institute of Technology Bombay\\Study\\Events and Activities\\Year 2\\Seasons of Coding 23\\soc23-DeepCarlsen\\final.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m5e-4\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m td_len \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m loss_history \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Indian%20Institute%20of%20Technology%20Bombay/Study/Events%20and%20Activities/Year%202/Seasons%20of%20Coding%2023/soc23-DeepCarlsen/final.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(dataset, model):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 2\n",
    "learning_rate = 5e-4\n",
    "td_len = 1\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss_history = []\n",
    "\n",
    "def step(dataset, model):\n",
    "    return 0\n",
    "    return loss_list/len(dataset)\n",
    "\n",
    "# The training loop!\n",
    "for epoch in range(num_epochs):\n",
    "  for idx in range(len(dataset)//batch_size):\n",
    "    # Grab a batch of training data and propagate through the network\n",
    "\n",
    "    def best_move(board, model):\n",
    "        turn = int(board.turn==chess.WHITE)\n",
    "        moves_set = board.legal_moves\n",
    "        moves_set2 = []\n",
    "        eval_set = []\n",
    "        #try:\n",
    "        for move in moves_set:\n",
    "            board.push(move)\n",
    "            fen = board.fen()\n",
    "            x1,x2,x3 = feat_ex(fen)\n",
    "            eval_set.append(eval_model([tens(el) for el in [x1,x2,x3]]))\n",
    "            moves_set2.append(move)\n",
    "            board.pop()\n",
    "        #except:\n",
    "            #return move, 7000\n",
    "        res = max(eval_set) if turn else min(eval_set)\n",
    "        bmove = moves_set2[eval_set.index(res)]\n",
    "        return bmove, res\n",
    "             \n",
    "    with tf.GradientTape() as tape:\n",
    "        #tape.watch(eval_model.trainable_variables)\n",
    "        loss_list = 0\n",
    "        for row, element in dataset.iterrows():\n",
    "            with tape.stop_recording():\n",
    "                board = chess.Board(element[\"FEN\"])\n",
    "                fen = board.fen()\n",
    "                x1,x2,x3 = feat_ex(fen)\n",
    "            prev_res = eval_model([tens(el) for el in [x1,x2,x3]])\n",
    "            with tape.stop_recording():\n",
    "                loss = 0\n",
    "                lmda = 0.7\n",
    "                #for move_td in range(td_len):\n",
    "                bmove, res = best_move(board, eval_model)\n",
    "                board.push(bmove)\n",
    "                loss = lmda*loss+(res-prev_res)**2\n",
    "                prev_res = res\n",
    "                loss_list+=loss\n",
    "    total_loss = loss_list/len(dataset)\n",
    "    grads = tape.gradient(total_loss, eval_model.trainable_variables)\n",
    "    print(grads)\n",
    "    print(total_loss)\n",
    "    optimizer.apply_gradients(zip(grads, eval_model.trainable_variables))\n",
    "    print(\"Epoch=\"+str(epoch)+\"/\"+str(num_epochs)+\"      idx*b=\"+str(idx*batch_size)+\"/\"+str(1000)+\"      Loss=\"+str(total_loss))\n",
    "    # Record the loss and plot the evolution of the loss as a function of training\n",
    "    loss_history.append(total_loss)\n",
    "\n",
    "loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>. . . . . . . .\n",
       ". p . . . . n k\n",
       "p . . . . . . .\n",
       "P . . Q p . . q\n",
       ". K P B . . . .\n",
       ". P . . . . . .\n",
       ". . . . . . . .\n",
       ". . . . . . . .</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 240)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(60, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 195)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(150, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 150)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 150)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(330, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 60)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(330, 60)\" /></svg>"
      ],
      "text/plain": [
       "Board('8/1p4nk/p7/P2Qp2q/1KPB4/1P6/8/8 w - - 0 53')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess.Board(\"6Q1/1p4nk/p7/P3p2q/1KPB4/1P6/8/8 b - - 1 53\")\n",
    "chess.Board(\"8/1p4nk/p7/P2Qp2q/1KPB4/1P6/8/8 w - - 0 53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>. . r . . r k .\n",
       "p b q n . p p p\n",
       ". p . . p n . B\n",
       ". . . . . . . .\n",
       ". . B P . . . .\n",
       ". . P Q . . . .\n",
       "P . . N . P P P\n",
       ". . . R . R K .</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(150, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(240, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(285, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 240)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 240)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(240, 105)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(330, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(60, 60)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(105, 60)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(105, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(240, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(285, 15)\" /></svg>"
      ],
      "text/plain": [
       "Board('2r2rk1/pbqn1ppp/1p2pn1B/8/2BP4/2PQ4/P2N1PPP/3R1RK1 w - - 0 1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess.Board(\"2r2rk1/pbqn1ppp/1p2pn1B/8/2BP4/2PQ4/P2N1PPP/3R1RK1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
